You are using CUDA.
Number of sentences loaded: 41479
Using PRPN, unsupervised.
Using gate values for parsing.
Using the parsing network from Shen et al.
Number of training batches: 2481
/beegfs/kk120/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/beegfs/kk120/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
main.py:235: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 1.)
Epoch: 0 -- batch: 0
Epoch: 0 -- batch: 100
Epoch: 0 -- batch: 200
Epoch: 0 -- batch: 300
Epoch: 0 -- batch: 400
Epoch: 0 -- batch: 500
Epoch: 0 -- batch: 600
Epoch: 0 -- batch: 700
Epoch: 0 -- batch: 800
Epoch: 0 -- batch: 900
Epoch: 0 -- batch: 1000
Epoch: 0 -- batch: 1100
Epoch: 0 -- batch: 1200
Epoch: 0 -- batch: 1300
Epoch: 0 -- batch: 1400
Epoch: 0 -- batch: 1500
Epoch: 0 -- batch: 1600
Epoch: 0 -- batch: 1700
Epoch: 0 -- batch: 1800
Epoch: 0 -- batch: 1900
Epoch: 0 -- batch: 2000
Epoch: 0 -- batch: 2100
Epoch: 0 -- batch: 2200
Epoch: 0 -- batch: 2300
Epoch: 0 -- batch: 2400
Training time for epoch in sec:  2351.4668
End of epoch 0. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(6.6751, device='cuda:0')
F1: 0.368706 (best: 0.368706)
Epoch: 1 -- batch: 0
Epoch: 1 -- batch: 100
Epoch: 1 -- batch: 200
Epoch: 1 -- batch: 300
Epoch: 1 -- batch: 400
Epoch: 1 -- batch: 500
Epoch: 1 -- batch: 600
Epoch: 1 -- batch: 700
Epoch: 1 -- batch: 800
Epoch: 1 -- batch: 900
Epoch: 1 -- batch: 1000
Epoch: 1 -- batch: 1100
Epoch: 1 -- batch: 1200
Epoch: 1 -- batch: 1300
Epoch: 1 -- batch: 1400
Epoch: 1 -- batch: 1500
Epoch: 1 -- batch: 1600
Epoch: 1 -- batch: 1700
Epoch: 1 -- batch: 1800
Epoch: 1 -- batch: 1900
Epoch: 1 -- batch: 2000
Epoch: 1 -- batch: 2100
Epoch: 1 -- batch: 2200
Epoch: 1 -- batch: 2300
Epoch: 1 -- batch: 2400
Training time for epoch in sec:  2503.8956
End of epoch 1. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.8785, device='cuda:0')
F1: 0.383386 (best: 0.383386)
Epoch: 2 -- batch: 0
Epoch: 2 -- batch: 100
Epoch: 2 -- batch: 200
Epoch: 2 -- batch: 300
Epoch: 2 -- batch: 400
Epoch: 2 -- batch: 500
Epoch: 2 -- batch: 600
Epoch: 2 -- batch: 700
Epoch: 2 -- batch: 800
Epoch: 2 -- batch: 900
Epoch: 2 -- batch: 1000
Epoch: 2 -- batch: 1100
Epoch: 2 -- batch: 1200
Epoch: 2 -- batch: 1300
Epoch: 2 -- batch: 1400
Epoch: 2 -- batch: 1500
Epoch: 2 -- batch: 1600
Epoch: 2 -- batch: 1700
Epoch: 2 -- batch: 1800
Epoch: 2 -- batch: 1900
Epoch: 2 -- batch: 2000
Epoch: 2 -- batch: 2100
Epoch: 2 -- batch: 2200
Epoch: 2 -- batch: 2300
Epoch: 2 -- batch: 2400
Training time for epoch in sec:  2513.878
End of epoch 2. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.5490, device='cuda:0')
F1: 0.384335 (best: 0.384335)
Epoch: 3 -- batch: 0
Epoch: 3 -- batch: 100
Epoch: 3 -- batch: 200
Epoch: 3 -- batch: 300
Epoch: 3 -- batch: 400
Epoch: 3 -- batch: 500
Epoch: 3 -- batch: 600
Epoch: 3 -- batch: 700
Epoch: 3 -- batch: 800
Epoch: 3 -- batch: 900
Epoch: 3 -- batch: 1000
Epoch: 3 -- batch: 1100
Epoch: 3 -- batch: 1200
Epoch: 3 -- batch: 1300
Epoch: 3 -- batch: 1400
Epoch: 3 -- batch: 1500
Epoch: 3 -- batch: 1600
Epoch: 3 -- batch: 1700
Epoch: 3 -- batch: 1800
Epoch: 3 -- batch: 1900
Epoch: 3 -- batch: 2000
Epoch: 3 -- batch: 2100
Epoch: 3 -- batch: 2200
Epoch: 3 -- batch: 2300
Epoch: 3 -- batch: 2400
Training time for epoch in sec:  2514.622
End of epoch 3. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.3459, device='cuda:0')
F1: 0.406572 (best: 0.406572)
Epoch: 4 -- batch: 0
Epoch: 4 -- batch: 100
Epoch: 4 -- batch: 200
Epoch: 4 -- batch: 300
Epoch: 4 -- batch: 400
Epoch: 4 -- batch: 500
Epoch: 4 -- batch: 600
Epoch: 4 -- batch: 700
Epoch: 4 -- batch: 800
Epoch: 4 -- batch: 900
Epoch: 4 -- batch: 1000
Epoch: 4 -- batch: 1100
Epoch: 4 -- batch: 1200
Epoch: 4 -- batch: 1300
Epoch: 4 -- batch: 1400
Epoch: 4 -- batch: 1500
Epoch: 4 -- batch: 1600
Epoch: 4 -- batch: 1700
Epoch: 4 -- batch: 1800
Epoch: 4 -- batch: 1900
Epoch: 4 -- batch: 2000
Epoch: 4 -- batch: 2100
Epoch: 4 -- batch: 2200
Epoch: 4 -- batch: 2300
Epoch: 4 -- batch: 2400
Training time for epoch in sec:  2514.9435
End of epoch 4. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.2031, device='cuda:0')
F1: 0.422728 (best: 0.422728)
Epoch: 5 -- batch: 0
Epoch: 5 -- batch: 100
Epoch: 5 -- batch: 200
Epoch: 5 -- batch: 300
Epoch: 5 -- batch: 400
Epoch: 5 -- batch: 500
Epoch: 5 -- batch: 600
Epoch: 5 -- batch: 700
Epoch: 5 -- batch: 800
Epoch: 5 -- batch: 900
Epoch: 5 -- batch: 1000
Epoch: 5 -- batch: 1100
Epoch: 5 -- batch: 1200
Epoch: 5 -- batch: 1300
Epoch: 5 -- batch: 1400
Epoch: 5 -- batch: 1500
Epoch: 5 -- batch: 1600
Epoch: 5 -- batch: 1700
Epoch: 5 -- batch: 1800
Epoch: 5 -- batch: 1900
Epoch: 5 -- batch: 2000
Epoch: 5 -- batch: 2100
Epoch: 5 -- batch: 2200
Epoch: 5 -- batch: 2300
Epoch: 5 -- batch: 2400
Training time for epoch in sec:  2510.7704
End of epoch 5. Evaluation on dev.
Storing current model...
Loss: tensor(5.0807, device='cuda:0')
F1: 0.41142 (best: 0.422728)
Epoch: 6 -- batch: 0
Epoch: 6 -- batch: 100
Epoch: 6 -- batch: 200
Epoch: 6 -- batch: 300
Epoch: 6 -- batch: 400
Epoch: 6 -- batch: 500
Epoch: 6 -- batch: 600
Epoch: 6 -- batch: 700
Epoch: 6 -- batch: 800
Epoch: 6 -- batch: 900
Epoch: 6 -- batch: 1000
Epoch: 6 -- batch: 1100
Epoch: 6 -- batch: 1200
Epoch: 6 -- batch: 1300
Epoch: 6 -- batch: 1400
Epoch: 6 -- batch: 1500
Epoch: 6 -- batch: 1600
Epoch: 6 -- batch: 1700
Epoch: 6 -- batch: 1800
Epoch: 6 -- batch: 1900
Epoch: 6 -- batch: 2000
Epoch: 6 -- batch: 2100
Epoch: 6 -- batch: 2200
Epoch: 6 -- batch: 2300
Epoch: 6 -- batch: 2400
Training time for epoch in sec:  2525.3313
End of epoch 6. Evaluation on dev.
Storing current model...
Loss: tensor(4.9783, device='cuda:0')
F1: 0.420621 (best: 0.422728)
Epoch: 7 -- batch: 0
Epoch: 7 -- batch: 100
Epoch: 7 -- batch: 200
Epoch: 7 -- batch: 300
Epoch: 7 -- batch: 400
Epoch: 7 -- batch: 500
Epoch: 7 -- batch: 600
Epoch: 7 -- batch: 700
Epoch: 7 -- batch: 800
Epoch: 7 -- batch: 900
Epoch: 7 -- batch: 1000
Epoch: 7 -- batch: 1100
Epoch: 7 -- batch: 1200
Epoch: 7 -- batch: 1300
Epoch: 7 -- batch: 1400
Epoch: 7 -- batch: 1500
Epoch: 7 -- batch: 1600
Epoch: 7 -- batch: 1700
Epoch: 7 -- batch: 1800
Epoch: 7 -- batch: 1900
Epoch: 7 -- batch: 2000
Epoch: 7 -- batch: 2100
Epoch: 7 -- batch: 2200
Epoch: 7 -- batch: 2300
Epoch: 7 -- batch: 2400
Training time for epoch in sec:  2525.299
End of epoch 7. Evaluation on dev.
Storing current model...
Loss: tensor(4.8893, device='cuda:0')
F1: 0.414082 (best: 0.422728)
Epoch: 8 -- batch: 0
Epoch: 8 -- batch: 100
Epoch: 8 -- batch: 200
Epoch: 8 -- batch: 300
Epoch: 8 -- batch: 400
Epoch: 8 -- batch: 500
Epoch: 8 -- batch: 600
Epoch: 8 -- batch: 700
Epoch: 8 -- batch: 800
Epoch: 8 -- batch: 900
Epoch: 8 -- batch: 1000
Epoch: 8 -- batch: 1100
Epoch: 8 -- batch: 1200
Epoch: 8 -- batch: 1300
Epoch: 8 -- batch: 1400
Epoch: 8 -- batch: 1500
Epoch: 8 -- batch: 1600
Epoch: 8 -- batch: 1700
Epoch: 8 -- batch: 1800
Epoch: 8 -- batch: 1900
Epoch: 8 -- batch: 2000
Epoch: 8 -- batch: 2100
Epoch: 8 -- batch: 2200
Epoch: 8 -- batch: 2300
Epoch: 8 -- batch: 2400
Training time for epoch in sec:  2515.6444
End of epoch 8. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.8087, device='cuda:0')
F1: 0.423777 (best: 0.423777)
Epoch: 9 -- batch: 0
Epoch: 9 -- batch: 100
Epoch: 9 -- batch: 200
Epoch: 9 -- batch: 300
Epoch: 9 -- batch: 400
Epoch: 9 -- batch: 500
Epoch: 9 -- batch: 600
Epoch: 9 -- batch: 700
Epoch: 9 -- batch: 800
Epoch: 9 -- batch: 900
Epoch: 9 -- batch: 1000
Epoch: 9 -- batch: 1100
Epoch: 9 -- batch: 1200
Epoch: 9 -- batch: 1300
Epoch: 9 -- batch: 1400
Epoch: 9 -- batch: 1500
Epoch: 9 -- batch: 1600
Epoch: 9 -- batch: 1700
Epoch: 9 -- batch: 1800
Epoch: 9 -- batch: 1900
Epoch: 9 -- batch: 2000
Epoch: 9 -- batch: 2100
Epoch: 9 -- batch: 2200
Epoch: 9 -- batch: 2300
Epoch: 9 -- batch: 2400
Training time for epoch in sec:  2510.6109
End of epoch 9. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.7302, device='cuda:0')
F1: 0.425209 (best: 0.425209)
Epoch: 10 -- batch: 0
Epoch: 10 -- batch: 100
Epoch: 10 -- batch: 200
Epoch: 10 -- batch: 300
Epoch: 10 -- batch: 400
Epoch: 10 -- batch: 500
Epoch: 10 -- batch: 600
Epoch: 10 -- batch: 700
Epoch: 10 -- batch: 800
Epoch: 10 -- batch: 900
Epoch: 10 -- batch: 1000
Epoch: 10 -- batch: 1100
Epoch: 10 -- batch: 1200
Epoch: 10 -- batch: 1300
Epoch: 10 -- batch: 1400
Epoch: 10 -- batch: 1500
Epoch: 10 -- batch: 1600
Epoch: 10 -- batch: 1700
Epoch: 10 -- batch: 1800
Epoch: 10 -- batch: 1900
Epoch: 10 -- batch: 2000
Epoch: 10 -- batch: 2100
Epoch: 10 -- batch: 2200
Epoch: 10 -- batch: 2300
Epoch: 10 -- batch: 2400
Training time for epoch in sec:  2514.879
End of epoch 10. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.6598, device='cuda:0')
F1: 0.442062 (best: 0.442062)
Epoch: 11 -- batch: 0
Epoch: 11 -- batch: 100
Epoch: 11 -- batch: 200
Epoch: 11 -- batch: 300
Epoch: 11 -- batch: 400
Epoch: 11 -- batch: 500
Epoch: 11 -- batch: 600
Epoch: 11 -- batch: 700
Epoch: 11 -- batch: 800
Epoch: 11 -- batch: 900
Epoch: 11 -- batch: 1000
Epoch: 11 -- batch: 1100
Epoch: 11 -- batch: 1200
Epoch: 11 -- batch: 1300
Epoch: 11 -- batch: 1400
Epoch: 11 -- batch: 1500
Epoch: 11 -- batch: 1600
Epoch: 11 -- batch: 1700
Epoch: 11 -- batch: 1800
Epoch: 11 -- batch: 1900
Epoch: 11 -- batch: 2000
Epoch: 11 -- batch: 2100
Epoch: 11 -- batch: 2200
Epoch: 11 -- batch: 2300
Epoch: 11 -- batch: 2400
Training time for epoch in sec:  2514.4974
End of epoch 11. Evaluation on dev.
Storing current model...
Loss: tensor(4.5981, device='cuda:0')
F1: 0.437599 (best: 0.442062)
Epoch: 12 -- batch: 0
Epoch: 12 -- batch: 100
Epoch: 12 -- batch: 200
Epoch: 12 -- batch: 300
Epoch: 12 -- batch: 400
Epoch: 12 -- batch: 500
Epoch: 12 -- batch: 600
Epoch: 12 -- batch: 700
Epoch: 12 -- batch: 800
Epoch: 12 -- batch: 900
Epoch: 12 -- batch: 1000
Epoch: 12 -- batch: 1100
Epoch: 12 -- batch: 1200
Epoch: 12 -- batch: 1300
Epoch: 12 -- batch: 1400
Epoch: 12 -- batch: 1500
Epoch: 12 -- batch: 1600
Epoch: 12 -- batch: 1700
Epoch: 12 -- batch: 1800
Epoch: 12 -- batch: 1900
Epoch: 12 -- batch: 2000
Epoch: 12 -- batch: 2100
Epoch: 12 -- batch: 2200
Epoch: 12 -- batch: 2300
Epoch: 12 -- batch: 2400
Training time for epoch in sec:  2511.2562
End of epoch 12. Evaluation on dev.
Storing current model...
Loss: tensor(4.5411, device='cuda:0')
F1: 0.429919 (best: 0.442062)
Epoch: 13 -- batch: 0
Epoch: 13 -- batch: 100
Epoch: 13 -- batch: 200
Epoch: 13 -- batch: 300
Epoch: 13 -- batch: 400
Epoch: 13 -- batch: 500
Epoch: 13 -- batch: 600
Epoch: 13 -- batch: 700
Epoch: 13 -- batch: 800
Epoch: 13 -- batch: 900
Epoch: 13 -- batch: 1000
Epoch: 13 -- batch: 1100
Epoch: 13 -- batch: 1200
Epoch: 13 -- batch: 1300
Epoch: 13 -- batch: 1400
Epoch: 13 -- batch: 1500
Epoch: 13 -- batch: 1600
Epoch: 13 -- batch: 1700
Epoch: 13 -- batch: 1800
Epoch: 13 -- batch: 1900
Epoch: 13 -- batch: 2000
Epoch: 13 -- batch: 2100
Epoch: 13 -- batch: 2200
Epoch: 13 -- batch: 2300
Epoch: 13 -- batch: 2400
Training time for epoch in sec:  2513.3149
End of epoch 13. Evaluation on dev.
Storing current model...
Loss: tensor(4.4892, device='cuda:0')
F1: 0.440687 (best: 0.442062)
Epoch: 14 -- batch: 0
Epoch: 14 -- batch: 100
Epoch: 14 -- batch: 200
Epoch: 14 -- batch: 300
Epoch: 14 -- batch: 400
Epoch: 14 -- batch: 500
Epoch: 14 -- batch: 600
Epoch: 14 -- batch: 700
Epoch: 14 -- batch: 800
Epoch: 14 -- batch: 900
Epoch: 14 -- batch: 1000
Epoch: 14 -- batch: 1100
Epoch: 14 -- batch: 1200
Epoch: 14 -- batch: 1300
Epoch: 14 -- batch: 1400
Epoch: 14 -- batch: 1500
Epoch: 14 -- batch: 1600
Epoch: 14 -- batch: 1700
Epoch: 14 -- batch: 1800
Epoch: 14 -- batch: 1900
Epoch: 14 -- batch: 2000
Epoch: 14 -- batch: 2100
Epoch: 14 -- batch: 2200
Epoch: 14 -- batch: 2300
Epoch: 14 -- batch: 2400
Training time for epoch in sec:  2516.4766
End of epoch 14. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.4401, device='cuda:0')
F1: 0.44469 (best: 0.44469)
Epoch: 15 -- batch: 0
Epoch: 15 -- batch: 100
Epoch: 15 -- batch: 200
Epoch: 15 -- batch: 300
Epoch: 15 -- batch: 400
Epoch: 15 -- batch: 500
Epoch: 15 -- batch: 600
Epoch: 15 -- batch: 700
Epoch: 15 -- batch: 800
Epoch: 15 -- batch: 900
Epoch: 15 -- batch: 1000
Epoch: 15 -- batch: 1100
Epoch: 15 -- batch: 1200
Epoch: 15 -- batch: 1300
Epoch: 15 -- batch: 1400
Epoch: 15 -- batch: 1500
Epoch: 15 -- batch: 1600
Epoch: 15 -- batch: 1700
Epoch: 15 -- batch: 1800
Epoch: 15 -- batch: 1900
Epoch: 15 -- batch: 2000
Epoch: 15 -- batch: 2100
Epoch: 15 -- batch: 2200
Epoch: 15 -- batch: 2300
Epoch: 15 -- batch: 2400
Training time for epoch in sec:  2514.1025
End of epoch 15. Evaluation on dev.
Storing current model...
Loss: tensor(4.3948, device='cuda:0')
F1: 0.437874 (best: 0.44469)
Epoch: 16 -- batch: 0
Epoch: 16 -- batch: 100
Epoch: 16 -- batch: 200
Epoch: 16 -- batch: 300
Epoch: 16 -- batch: 400
Epoch: 16 -- batch: 500
Epoch: 16 -- batch: 600
Epoch: 16 -- batch: 700
Epoch: 16 -- batch: 800
Epoch: 16 -- batch: 900
Epoch: 16 -- batch: 1000
Epoch: 16 -- batch: 1100
Epoch: 16 -- batch: 1200
Epoch: 16 -- batch: 1300
Epoch: 16 -- batch: 1400
Epoch: 16 -- batch: 1500
Epoch: 16 -- batch: 1600
Epoch: 16 -- batch: 1700
Epoch: 16 -- batch: 1800
Epoch: 16 -- batch: 1900
Epoch: 16 -- batch: 2000
Epoch: 16 -- batch: 2100
Epoch: 16 -- batch: 2200
Epoch: 16 -- batch: 2300
Epoch: 16 -- batch: 2400
Training time for epoch in sec:  2516.1462
End of epoch 16. Evaluation on dev.
Storing current model...
Loss: tensor(4.3508, device='cuda:0')
F1: 0.444288 (best: 0.44469)
Epoch: 17 -- batch: 0
Epoch: 17 -- batch: 100
Epoch: 17 -- batch: 200
Epoch: 17 -- batch: 300
Epoch: 17 -- batch: 400
Epoch: 17 -- batch: 500
Epoch: 17 -- batch: 600
Epoch: 17 -- batch: 700
Epoch: 17 -- batch: 800
Epoch: 17 -- batch: 900
Epoch: 17 -- batch: 1000
Epoch: 17 -- batch: 1100
Epoch: 17 -- batch: 1200
Epoch: 17 -- batch: 1300
Epoch: 17 -- batch: 1400
Epoch: 17 -- batch: 1500
Epoch: 17 -- batch: 1600
Epoch: 17 -- batch: 1700
Epoch: 17 -- batch: 1800
Epoch: 17 -- batch: 1900
Epoch: 17 -- batch: 2000
Epoch: 17 -- batch: 2100
Epoch: 17 -- batch: 2200
Epoch: 17 -- batch: 2300
Epoch: 17 -- batch: 2400
Training time for epoch in sec:  2510.3614
End of epoch 17. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.3142, device='cuda:0')
F1: 0.453395 (best: 0.453395)
Epoch: 18 -- batch: 0
Epoch: 18 -- batch: 100
Epoch: 18 -- batch: 200
Epoch: 18 -- batch: 300
Epoch: 18 -- batch: 400
Epoch: 18 -- batch: 500
Epoch: 18 -- batch: 600
Epoch: 18 -- batch: 700
Epoch: 18 -- batch: 800
Epoch: 18 -- batch: 900
Epoch: 18 -- batch: 1000
Epoch: 18 -- batch: 1100
Epoch: 18 -- batch: 1200
Epoch: 18 -- batch: 1300
Epoch: 18 -- batch: 1400
Epoch: 18 -- batch: 1500
Epoch: 18 -- batch: 1600
Epoch: 18 -- batch: 1700
Epoch: 18 -- batch: 1800
Epoch: 18 -- batch: 1900
Epoch: 18 -- batch: 2000
Epoch: 18 -- batch: 2100
Epoch: 18 -- batch: 2200
Epoch: 18 -- batch: 2300
Epoch: 18 -- batch: 2400
Training time for epoch in sec:  2510.9512
End of epoch 18. Evaluation on dev.
Storing current model...
Loss: tensor(4.2778, device='cuda:0')
F1: 0.451367 (best: 0.453395)
Epoch: 19 -- batch: 0
Epoch: 19 -- batch: 100
Epoch: 19 -- batch: 200
Epoch: 19 -- batch: 300
Epoch: 19 -- batch: 400
Epoch: 19 -- batch: 500
Epoch: 19 -- batch: 600
Epoch: 19 -- batch: 700
Epoch: 19 -- batch: 800
Epoch: 19 -- batch: 900
Epoch: 19 -- batch: 1000
Epoch: 19 -- batch: 1100
Epoch: 19 -- batch: 1200
Epoch: 19 -- batch: 1300
Epoch: 19 -- batch: 1400
Epoch: 19 -- batch: 1500
Epoch: 19 -- batch: 1600
Epoch: 19 -- batch: 1700
Epoch: 19 -- batch: 1800
Epoch: 19 -- batch: 1900
Epoch: 19 -- batch: 2000
Epoch: 19 -- batch: 2100
Epoch: 19 -- batch: 2200
Epoch: 19 -- batch: 2300
Epoch: 19 -- batch: 2400
Training time for epoch in sec:  2510.588
End of epoch 19. Evaluation on dev.
Storing current model...
Loss: tensor(4.2429, device='cuda:0')
F1: 0.439454 (best: 0.453395)
Epoch: 20 -- batch: 0
Epoch: 20 -- batch: 100
Epoch: 20 -- batch: 200
Epoch: 20 -- batch: 300
Epoch: 20 -- batch: 400
Epoch: 20 -- batch: 500
Epoch: 20 -- batch: 600
Epoch: 20 -- batch: 700
Epoch: 20 -- batch: 800
Epoch: 20 -- batch: 900
Epoch: 20 -- batch: 1000
Epoch: 20 -- batch: 1100
Epoch: 20 -- batch: 1200
Epoch: 20 -- batch: 1300
Epoch: 20 -- batch: 1400
Epoch: 20 -- batch: 1500
Epoch: 20 -- batch: 1600
Epoch: 20 -- batch: 1700
Epoch: 20 -- batch: 1800
Epoch: 20 -- batch: 1900
Epoch: 20 -- batch: 2000
Epoch: 20 -- batch: 2100
Epoch: 20 -- batch: 2200
Epoch: 20 -- batch: 2300
Epoch: 20 -- batch: 2400
Training time for epoch in sec:  2509.5632
End of epoch 20. Evaluation on dev.
Storing current model...
Loss: tensor(4.2097, device='cuda:0')
F1: 0.447032 (best: 0.453395)
Epoch: 21 -- batch: 0
Epoch: 21 -- batch: 100
Epoch: 21 -- batch: 200
Epoch: 21 -- batch: 300
Epoch: 21 -- batch: 400
Epoch: 21 -- batch: 500
Epoch: 21 -- batch: 600
Epoch: 21 -- batch: 700
Epoch: 21 -- batch: 800
Epoch: 21 -- batch: 900
Epoch: 21 -- batch: 1000
Epoch: 21 -- batch: 1100
Epoch: 21 -- batch: 1200
Epoch: 21 -- batch: 1300
Epoch: 21 -- batch: 1400
Epoch: 21 -- batch: 1500
Epoch: 21 -- batch: 1600
Epoch: 21 -- batch: 1700
Epoch: 21 -- batch: 1800
Epoch: 21 -- batch: 1900
Epoch: 21 -- batch: 2000
Epoch: 21 -- batch: 2100
Epoch: 21 -- batch: 2200
Epoch: 21 -- batch: 2300
Epoch: 21 -- batch: 2400
Training time for epoch in sec:  2510.1251
End of epoch 21. Evaluation on dev.
Storing current model...
Loss: tensor(4.1782, device='cuda:0')
F1: 0.447701 (best: 0.453395)
Epoch: 22 -- batch: 0
Epoch: 22 -- batch: 100
Epoch: 22 -- batch: 200
Epoch: 22 -- batch: 300
Epoch: 22 -- batch: 400
Epoch: 22 -- batch: 500
Epoch: 22 -- batch: 600
Epoch: 22 -- batch: 700
Epoch: 22 -- batch: 800
Epoch: 22 -- batch: 900
Epoch: 22 -- batch: 1000
Epoch: 22 -- batch: 1100
Epoch: 22 -- batch: 1200
Epoch: 22 -- batch: 1300
Epoch: 22 -- batch: 1400
Epoch: 22 -- batch: 1500
Epoch: 22 -- batch: 1600
Epoch: 22 -- batch: 1700
Epoch: 22 -- batch: 1800
Epoch: 22 -- batch: 1900
Epoch: 22 -- batch: 2000
Epoch: 22 -- batch: 2100
Epoch: 22 -- batch: 2200
Epoch: 22 -- batch: 2300
Epoch: 22 -- batch: 2400
Training time for epoch in sec:  2512.5443
End of epoch 22. Evaluation on dev.
Storing current model...
Loss: tensor(4.1488, device='cuda:0')
F1: 0.447791 (best: 0.453395)
Epoch: 23 -- batch: 0
Epoch: 23 -- batch: 100
Epoch: 23 -- batch: 200
Epoch: 23 -- batch: 300
Epoch: 23 -- batch: 400
Epoch: 23 -- batch: 500
Epoch: 23 -- batch: 600
Epoch: 23 -- batch: 700
Epoch: 23 -- batch: 800
Epoch: 23 -- batch: 900
Epoch: 23 -- batch: 1000
Epoch: 23 -- batch: 1100
Epoch: 23 -- batch: 1200
Epoch: 23 -- batch: 1300
Epoch: 23 -- batch: 1400
Epoch: 23 -- batch: 1500
Epoch: 23 -- batch: 1600
Epoch: 23 -- batch: 1700
Epoch: 23 -- batch: 1800
Epoch: 23 -- batch: 1900
Epoch: 23 -- batch: 2000
Epoch: 23 -- batch: 2100
Epoch: 23 -- batch: 2200
Epoch: 23 -- batch: 2300
Epoch: 23 -- batch: 2400
Training time for epoch in sec:  2513.1185
End of epoch 23. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.1202, device='cuda:0')
F1: 0.458458 (best: 0.458458)
Epoch: 24 -- batch: 0
Epoch: 24 -- batch: 100
Epoch: 24 -- batch: 200
Epoch: 24 -- batch: 300
Epoch: 24 -- batch: 400
Epoch: 24 -- batch: 500
Epoch: 24 -- batch: 600
Epoch: 24 -- batch: 700
Epoch: 24 -- batch: 800
Epoch: 24 -- batch: 900
Epoch: 24 -- batch: 1000
Epoch: 24 -- batch: 1100
Epoch: 24 -- batch: 1200
Epoch: 24 -- batch: 1300
Epoch: 24 -- batch: 1400
Epoch: 24 -- batch: 1500
Epoch: 24 -- batch: 1600
Epoch: 24 -- batch: 1700
Epoch: 24 -- batch: 1800
Epoch: 24 -- batch: 1900
Epoch: 24 -- batch: 2000
Epoch: 24 -- batch: 2100
Epoch: 24 -- batch: 2200
Epoch: 24 -- batch: 2300
Epoch: 24 -- batch: 2400
Training time for epoch in sec:  2511.0676
End of epoch 24. Evaluation on dev.
Storing current model...
Loss: tensor(4.0929, device='cuda:0')
F1: 0.446018 (best: 0.458458)
Epoch: 25 -- batch: 0
Epoch: 25 -- batch: 100
Epoch: 25 -- batch: 200
Epoch: 25 -- batch: 300
Epoch: 25 -- batch: 400
Epoch: 25 -- batch: 500
Epoch: 25 -- batch: 600
Epoch: 25 -- batch: 700
Epoch: 25 -- batch: 800
Epoch: 25 -- batch: 900
Epoch: 25 -- batch: 1000
Epoch: 25 -- batch: 1100
Epoch: 25 -- batch: 1200
Epoch: 25 -- batch: 1300
Epoch: 25 -- batch: 1400
Epoch: 25 -- batch: 1500
Epoch: 25 -- batch: 1600
Epoch: 25 -- batch: 1700
Epoch: 25 -- batch: 1800
Epoch: 25 -- batch: 1900
Epoch: 25 -- batch: 2000
Epoch: 25 -- batch: 2100
Epoch: 25 -- batch: 2200
Epoch: 25 -- batch: 2300
Epoch: 25 -- batch: 2400
Training time for epoch in sec:  2510.5926
End of epoch 25. Evaluation on dev.
Storing current model...
Loss: tensor(4.0678, device='cuda:0')
F1: 0.451552 (best: 0.458458)
Epoch: 26 -- batch: 0
Epoch: 26 -- batch: 100
Epoch: 26 -- batch: 200
Epoch: 26 -- batch: 300
Epoch: 26 -- batch: 400
Epoch: 26 -- batch: 500
Epoch: 26 -- batch: 600
Epoch: 26 -- batch: 700
Epoch: 26 -- batch: 800
Epoch: 26 -- batch: 900
Epoch: 26 -- batch: 1000
Epoch: 26 -- batch: 1100
Epoch: 26 -- batch: 1200
Epoch: 26 -- batch: 1300
Epoch: 26 -- batch: 1400
Epoch: 26 -- batch: 1500
Epoch: 26 -- batch: 1600
Epoch: 26 -- batch: 1700
Epoch: 26 -- batch: 1800
Epoch: 26 -- batch: 1900
Epoch: 26 -- batch: 2000
Epoch: 26 -- batch: 2100
Epoch: 26 -- batch: 2200
Epoch: 26 -- batch: 2300
Epoch: 26 -- batch: 2400
Training time for epoch in sec:  2512.9401
End of epoch 26. Evaluation on dev.
Storing current model...
Loss: tensor(4.0451, device='cuda:0')
F1: 0.455165 (best: 0.458458)
Epoch: 27 -- batch: 0
Epoch: 27 -- batch: 100
Epoch: 27 -- batch: 200
Epoch: 27 -- batch: 300
Epoch: 27 -- batch: 400
Epoch: 27 -- batch: 500
Epoch: 27 -- batch: 600
Epoch: 27 -- batch: 700
Epoch: 27 -- batch: 800
Epoch: 27 -- batch: 900
Epoch: 27 -- batch: 1000
Epoch: 27 -- batch: 1100
Epoch: 27 -- batch: 1200
Epoch: 27 -- batch: 1300
Epoch: 27 -- batch: 1400
Epoch: 27 -- batch: 1500
Epoch: 27 -- batch: 1600
Epoch: 27 -- batch: 1700
Epoch: 27 -- batch: 1800
Epoch: 27 -- batch: 1900
Epoch: 27 -- batch: 2000
Epoch: 27 -- batch: 2100
Epoch: 27 -- batch: 2200
Epoch: 27 -- batch: 2300
Epoch: 27 -- batch: 2400
Training time for epoch in sec:  2511.4061
End of epoch 27. Evaluation on dev.
Storing current model...
Loss: tensor(4.0200, device='cuda:0')
F1: 0.452781 (best: 0.458458)
Epoch: 28 -- batch: 0
Epoch: 28 -- batch: 100
Epoch: 28 -- batch: 200
Epoch: 28 -- batch: 300
Epoch: 28 -- batch: 400
Epoch: 28 -- batch: 500
Epoch: 28 -- batch: 600
Epoch: 28 -- batch: 700
Epoch: 28 -- batch: 800
Epoch: 28 -- batch: 900
Epoch: 28 -- batch: 1000
Epoch: 28 -- batch: 1100
Epoch: 28 -- batch: 1200
Epoch: 28 -- batch: 1300
Epoch: 28 -- batch: 1400
Epoch: 28 -- batch: 1500
Epoch: 28 -- batch: 1600
Epoch: 28 -- batch: 1700
Epoch: 28 -- batch: 1800
Epoch: 28 -- batch: 1900
Epoch: 28 -- batch: 2000
Epoch: 28 -- batch: 2100
Epoch: 28 -- batch: 2200
Epoch: 28 -- batch: 2300
Epoch: 28 -- batch: 2400
Training time for epoch in sec:  2511.4867
End of epoch 28. Evaluation on dev.
Storing current model...
Loss: tensor(3.9978, device='cuda:0')
F1: 0.453526 (best: 0.458458)
Epoch: 29 -- batch: 0
Epoch: 29 -- batch: 100
Epoch: 29 -- batch: 200
Epoch: 29 -- batch: 300
Epoch: 29 -- batch: 400
Epoch: 29 -- batch: 500
Epoch: 29 -- batch: 600
Epoch: 29 -- batch: 700
Epoch: 29 -- batch: 800
Epoch: 29 -- batch: 900
Epoch: 29 -- batch: 1000
Epoch: 29 -- batch: 1100
Epoch: 29 -- batch: 1200
Epoch: 29 -- batch: 1300
Epoch: 29 -- batch: 1400
Epoch: 29 -- batch: 1500
Epoch: 29 -- batch: 1600
Epoch: 29 -- batch: 1700
Epoch: 29 -- batch: 1800
Epoch: 29 -- batch: 1900
Epoch: 29 -- batch: 2000
Epoch: 29 -- batch: 2100
Epoch: 29 -- batch: 2200
Epoch: 29 -- batch: 2300
Epoch: 29 -- batch: 2400
Training time for epoch in sec:  2511.5923
End of epoch 29. Evaluation on dev.
Storing current model...
Loss: tensor(3.9756, device='cuda:0')
F1: 0.455231 (best: 0.458458)
