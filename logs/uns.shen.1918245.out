You are using CUDA.
Number of sentences loaded: 41479
Using PRPN, unsupervised.
Using gate values for parsing.
Using the parsing network from Shen et al.
Number of training batches: 2481
/beegfs/kk120/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1386: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/beegfs/kk120/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1374: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
main.py:235: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.
  torch.nn.utils.clip_grad_norm(model.parameters(), 1.)
Epoch: 0 -- batch: 0
Epoch: 0 -- batch: 100
Epoch: 0 -- batch: 200
Epoch: 0 -- batch: 300
Epoch: 0 -- batch: 400
Epoch: 0 -- batch: 500
Epoch: 0 -- batch: 600
Epoch: 0 -- batch: 700
Epoch: 0 -- batch: 800
Epoch: 0 -- batch: 900
Epoch: 0 -- batch: 1000
Epoch: 0 -- batch: 1100
Epoch: 0 -- batch: 1200
Epoch: 0 -- batch: 1300
Epoch: 0 -- batch: 1400
Epoch: 0 -- batch: 1500
Epoch: 0 -- batch: 1600
Epoch: 0 -- batch: 1700
Epoch: 0 -- batch: 1800
Epoch: 0 -- batch: 1900
Epoch: 0 -- batch: 2000
Epoch: 0 -- batch: 2100
Epoch: 0 -- batch: 2200
Epoch: 0 -- batch: 2300
Epoch: 0 -- batch: 2400
Training time for epoch in sec:  2345.3864
End of epoch 0. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(6.6473, device='cuda:0')
F1: 0.406977 (best: 0.406977)
Epoch: 1 -- batch: 0
Epoch: 1 -- batch: 100
Epoch: 1 -- batch: 200
Epoch: 1 -- batch: 300
Epoch: 1 -- batch: 400
Epoch: 1 -- batch: 500
Epoch: 1 -- batch: 600
Epoch: 1 -- batch: 700
Epoch: 1 -- batch: 800
Epoch: 1 -- batch: 900
Epoch: 1 -- batch: 1000
Epoch: 1 -- batch: 1100
Epoch: 1 -- batch: 1200
Epoch: 1 -- batch: 1300
Epoch: 1 -- batch: 1400
Epoch: 1 -- batch: 1500
Epoch: 1 -- batch: 1600
Epoch: 1 -- batch: 1700
Epoch: 1 -- batch: 1800
Epoch: 1 -- batch: 1900
Epoch: 1 -- batch: 2000
Epoch: 1 -- batch: 2100
Epoch: 1 -- batch: 2200
Epoch: 1 -- batch: 2300
Epoch: 1 -- batch: 2400
Training time for epoch in sec:  2486.6669
End of epoch 1. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.8504, device='cuda:0')
F1: 0.413166 (best: 0.413166)
Epoch: 2 -- batch: 0
Epoch: 2 -- batch: 100
Epoch: 2 -- batch: 200
Epoch: 2 -- batch: 300
Epoch: 2 -- batch: 400
Epoch: 2 -- batch: 500
Epoch: 2 -- batch: 600
Epoch: 2 -- batch: 700
Epoch: 2 -- batch: 800
Epoch: 2 -- batch: 900
Epoch: 2 -- batch: 1000
Epoch: 2 -- batch: 1100
Epoch: 2 -- batch: 1200
Epoch: 2 -- batch: 1300
Epoch: 2 -- batch: 1400
Epoch: 2 -- batch: 1500
Epoch: 2 -- batch: 1600
Epoch: 2 -- batch: 1700
Epoch: 2 -- batch: 1800
Epoch: 2 -- batch: 1900
Epoch: 2 -- batch: 2000
Epoch: 2 -- batch: 2100
Epoch: 2 -- batch: 2200
Epoch: 2 -- batch: 2300
Epoch: 2 -- batch: 2400
Training time for epoch in sec:  2498.2862
End of epoch 2. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.5289, device='cuda:0')
F1: 0.439327 (best: 0.439327)
Epoch: 3 -- batch: 0
Epoch: 3 -- batch: 100
Epoch: 3 -- batch: 200
Epoch: 3 -- batch: 300
Epoch: 3 -- batch: 400
Epoch: 3 -- batch: 500
Epoch: 3 -- batch: 600
Epoch: 3 -- batch: 700
Epoch: 3 -- batch: 800
Epoch: 3 -- batch: 900
Epoch: 3 -- batch: 1000
Epoch: 3 -- batch: 1100
Epoch: 3 -- batch: 1200
Epoch: 3 -- batch: 1300
Epoch: 3 -- batch: 1400
Epoch: 3 -- batch: 1500
Epoch: 3 -- batch: 1600
Epoch: 3 -- batch: 1700
Epoch: 3 -- batch: 1800
Epoch: 3 -- batch: 1900
Epoch: 3 -- batch: 2000
Epoch: 3 -- batch: 2100
Epoch: 3 -- batch: 2200
Epoch: 3 -- batch: 2300
Epoch: 3 -- batch: 2400
Training time for epoch in sec:  2500.2259
End of epoch 3. Evaluation on dev.
Storing current model...
Loss: tensor(5.3177, device='cuda:0')
F1: 0.433956 (best: 0.439327)
Epoch: 4 -- batch: 0
Epoch: 4 -- batch: 100
Epoch: 4 -- batch: 200
Epoch: 4 -- batch: 300
Epoch: 4 -- batch: 400
Epoch: 4 -- batch: 500
Epoch: 4 -- batch: 600
Epoch: 4 -- batch: 700
Epoch: 4 -- batch: 800
Epoch: 4 -- batch: 900
Epoch: 4 -- batch: 1000
Epoch: 4 -- batch: 1100
Epoch: 4 -- batch: 1200
Epoch: 4 -- batch: 1300
Epoch: 4 -- batch: 1400
Epoch: 4 -- batch: 1500
Epoch: 4 -- batch: 1600
Epoch: 4 -- batch: 1700
Epoch: 4 -- batch: 1800
Epoch: 4 -- batch: 1900
Epoch: 4 -- batch: 2000
Epoch: 4 -- batch: 2100
Epoch: 4 -- batch: 2200
Epoch: 4 -- batch: 2300
Epoch: 4 -- batch: 2400
Training time for epoch in sec:  2499.6283
End of epoch 4. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.1605, device='cuda:0')
F1: 0.441897 (best: 0.441897)
Epoch: 5 -- batch: 0
Epoch: 5 -- batch: 100
Epoch: 5 -- batch: 200
Epoch: 5 -- batch: 300
Epoch: 5 -- batch: 400
Epoch: 5 -- batch: 500
Epoch: 5 -- batch: 600
Epoch: 5 -- batch: 700
Epoch: 5 -- batch: 800
Epoch: 5 -- batch: 900
Epoch: 5 -- batch: 1000
Epoch: 5 -- batch: 1100
Epoch: 5 -- batch: 1200
Epoch: 5 -- batch: 1300
Epoch: 5 -- batch: 1400
Epoch: 5 -- batch: 1500
Epoch: 5 -- batch: 1600
Epoch: 5 -- batch: 1700
Epoch: 5 -- batch: 1800
Epoch: 5 -- batch: 1900
Epoch: 5 -- batch: 2000
Epoch: 5 -- batch: 2100
Epoch: 5 -- batch: 2200
Epoch: 5 -- batch: 2300
Epoch: 5 -- batch: 2400
Training time for epoch in sec:  2496.3992
End of epoch 5. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(5.0315, device='cuda:0')
F1: 0.445575 (best: 0.445575)
Epoch: 6 -- batch: 0
Epoch: 6 -- batch: 100
Epoch: 6 -- batch: 200
Epoch: 6 -- batch: 300
Epoch: 6 -- batch: 400
Epoch: 6 -- batch: 500
Epoch: 6 -- batch: 600
Epoch: 6 -- batch: 700
Epoch: 6 -- batch: 800
Epoch: 6 -- batch: 900
Epoch: 6 -- batch: 1000
Epoch: 6 -- batch: 1100
Epoch: 6 -- batch: 1200
Epoch: 6 -- batch: 1300
Epoch: 6 -- batch: 1400
Epoch: 6 -- batch: 1500
Epoch: 6 -- batch: 1600
Epoch: 6 -- batch: 1700
Epoch: 6 -- batch: 1800
Epoch: 6 -- batch: 1900
Epoch: 6 -- batch: 2000
Epoch: 6 -- batch: 2100
Epoch: 6 -- batch: 2200
Epoch: 6 -- batch: 2300
Epoch: 6 -- batch: 2400
Training time for epoch in sec:  2499.2442
End of epoch 6. Evaluation on dev.
Storing current model...
Loss: tensor(4.9245, device='cuda:0')
F1: 0.443015 (best: 0.445575)
Epoch: 7 -- batch: 0
Epoch: 7 -- batch: 100
Epoch: 7 -- batch: 200
Epoch: 7 -- batch: 300
Epoch: 7 -- batch: 400
Epoch: 7 -- batch: 500
Epoch: 7 -- batch: 600
Epoch: 7 -- batch: 700
Epoch: 7 -- batch: 800
Epoch: 7 -- batch: 900
Epoch: 7 -- batch: 1000
Epoch: 7 -- batch: 1100
Epoch: 7 -- batch: 1200
Epoch: 7 -- batch: 1300
Epoch: 7 -- batch: 1400
Epoch: 7 -- batch: 1500
Epoch: 7 -- batch: 1600
Epoch: 7 -- batch: 1700
Epoch: 7 -- batch: 1800
Epoch: 7 -- batch: 1900
Epoch: 7 -- batch: 2000
Epoch: 7 -- batch: 2100
Epoch: 7 -- batch: 2200
Epoch: 7 -- batch: 2300
Epoch: 7 -- batch: 2400
Training time for epoch in sec:  2499.4489
End of epoch 7. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.8298, device='cuda:0')
F1: 0.449393 (best: 0.449393)
Epoch: 8 -- batch: 0
Epoch: 8 -- batch: 100
Epoch: 8 -- batch: 200
Epoch: 8 -- batch: 300
Epoch: 8 -- batch: 400
Epoch: 8 -- batch: 500
Epoch: 8 -- batch: 600
Epoch: 8 -- batch: 700
Epoch: 8 -- batch: 800
Epoch: 8 -- batch: 900
Epoch: 8 -- batch: 1000
Epoch: 8 -- batch: 1100
Epoch: 8 -- batch: 1200
Epoch: 8 -- batch: 1300
Epoch: 8 -- batch: 1400
Epoch: 8 -- batch: 1500
Epoch: 8 -- batch: 1600
Epoch: 8 -- batch: 1700
Epoch: 8 -- batch: 1800
Epoch: 8 -- batch: 1900
Epoch: 8 -- batch: 2000
Epoch: 8 -- batch: 2100
Epoch: 8 -- batch: 2200
Epoch: 8 -- batch: 2300
Epoch: 8 -- batch: 2400
Training time for epoch in sec:  2499.993
End of epoch 8. Evaluation on dev.
Storing current model...
Loss: tensor(4.7499, device='cuda:0')
F1: 0.447956 (best: 0.449393)
Epoch: 9 -- batch: 0
Epoch: 9 -- batch: 100
Epoch: 9 -- batch: 200
Epoch: 9 -- batch: 300
Epoch: 9 -- batch: 400
Epoch: 9 -- batch: 500
Epoch: 9 -- batch: 600
Epoch: 9 -- batch: 700
Epoch: 9 -- batch: 800
Epoch: 9 -- batch: 900
Epoch: 9 -- batch: 1000
Epoch: 9 -- batch: 1100
Epoch: 9 -- batch: 1200
Epoch: 9 -- batch: 1300
Epoch: 9 -- batch: 1400
Epoch: 9 -- batch: 1500
Epoch: 9 -- batch: 1600
Epoch: 9 -- batch: 1700
Epoch: 9 -- batch: 1800
Epoch: 9 -- batch: 1900
Epoch: 9 -- batch: 2000
Epoch: 9 -- batch: 2100
Epoch: 9 -- batch: 2200
Epoch: 9 -- batch: 2300
Epoch: 9 -- batch: 2400
Training time for epoch in sec:  2500.2045
End of epoch 9. Evaluation on dev.
Storing current model...
Loss: tensor(4.6752, device='cuda:0')
F1: 0.445183 (best: 0.449393)
Epoch: 10 -- batch: 0
Epoch: 10 -- batch: 100
Epoch: 10 -- batch: 200
Epoch: 10 -- batch: 300
Epoch: 10 -- batch: 400
Epoch: 10 -- batch: 500
Epoch: 10 -- batch: 600
Epoch: 10 -- batch: 700
Epoch: 10 -- batch: 800
Epoch: 10 -- batch: 900
Epoch: 10 -- batch: 1000
Epoch: 10 -- batch: 1100
Epoch: 10 -- batch: 1200
Epoch: 10 -- batch: 1300
Epoch: 10 -- batch: 1400
Epoch: 10 -- batch: 1500
Epoch: 10 -- batch: 1600
Epoch: 10 -- batch: 1700
Epoch: 10 -- batch: 1800
Epoch: 10 -- batch: 1900
Epoch: 10 -- batch: 2000
Epoch: 10 -- batch: 2100
Epoch: 10 -- batch: 2200
Epoch: 10 -- batch: 2300
Epoch: 10 -- batch: 2400
Training time for epoch in sec:  2499.2752
End of epoch 10. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.6114, device='cuda:0')
F1: 0.451049 (best: 0.451049)
Epoch: 11 -- batch: 0
Epoch: 11 -- batch: 100
Epoch: 11 -- batch: 200
Epoch: 11 -- batch: 300
Epoch: 11 -- batch: 400
Epoch: 11 -- batch: 500
Epoch: 11 -- batch: 600
Epoch: 11 -- batch: 700
Epoch: 11 -- batch: 800
Epoch: 11 -- batch: 900
Epoch: 11 -- batch: 1000
Epoch: 11 -- batch: 1100
Epoch: 11 -- batch: 1200
Epoch: 11 -- batch: 1300
Epoch: 11 -- batch: 1400
Epoch: 11 -- batch: 1500
Epoch: 11 -- batch: 1600
Epoch: 11 -- batch: 1700
Epoch: 11 -- batch: 1800
Epoch: 11 -- batch: 1900
Epoch: 11 -- batch: 2000
Epoch: 11 -- batch: 2100
Epoch: 11 -- batch: 2200
Epoch: 11 -- batch: 2300
Epoch: 11 -- batch: 2400
Training time for epoch in sec:  2498.9209
End of epoch 11. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.5525, device='cuda:0')
F1: 0.457492 (best: 0.457492)
Epoch: 12 -- batch: 0
Epoch: 12 -- batch: 100
Epoch: 12 -- batch: 200
Epoch: 12 -- batch: 300
Epoch: 12 -- batch: 400
Epoch: 12 -- batch: 500
Epoch: 12 -- batch: 600
Epoch: 12 -- batch: 700
Epoch: 12 -- batch: 800
Epoch: 12 -- batch: 900
Epoch: 12 -- batch: 1000
Epoch: 12 -- batch: 1100
Epoch: 12 -- batch: 1200
Epoch: 12 -- batch: 1300
Epoch: 12 -- batch: 1400
Epoch: 12 -- batch: 1500
Epoch: 12 -- batch: 1600
Epoch: 12 -- batch: 1700
Epoch: 12 -- batch: 1800
Epoch: 12 -- batch: 1900
Epoch: 12 -- batch: 2000
Epoch: 12 -- batch: 2100
Epoch: 12 -- batch: 2200
Epoch: 12 -- batch: 2300
Epoch: 12 -- batch: 2400
Training time for epoch in sec:  2499.8967
End of epoch 12. Evaluation on dev.
Storing current model...
Storing new best model...
Loss: tensor(4.4955, device='cuda:0')
F1: 0.462459 (best: 0.462459)
Epoch: 13 -- batch: 0
Epoch: 13 -- batch: 100
Epoch: 13 -- batch: 200
Epoch: 13 -- batch: 300
Epoch: 13 -- batch: 400
Epoch: 13 -- batch: 500
Epoch: 13 -- batch: 600
Epoch: 13 -- batch: 700
Epoch: 13 -- batch: 800
Epoch: 13 -- batch: 900
Epoch: 13 -- batch: 1000
Epoch: 13 -- batch: 1100
Epoch: 13 -- batch: 1200
Epoch: 13 -- batch: 1300
Epoch: 13 -- batch: 1400
Epoch: 13 -- batch: 1500
Epoch: 13 -- batch: 1600
Epoch: 13 -- batch: 1700
Epoch: 13 -- batch: 1800
Epoch: 13 -- batch: 1900
Epoch: 13 -- batch: 2000
Epoch: 13 -- batch: 2100
Epoch: 13 -- batch: 2200
Epoch: 13 -- batch: 2300
Epoch: 13 -- batch: 2400
Training time for epoch in sec:  2499.6643
End of epoch 13. Evaluation on dev.
Storing current model...
Loss: tensor(4.4448, device='cuda:0')
F1: 0.451073 (best: 0.462459)
Epoch: 14 -- batch: 0
Epoch: 14 -- batch: 100
Epoch: 14 -- batch: 200
Epoch: 14 -- batch: 300
Epoch: 14 -- batch: 400
Epoch: 14 -- batch: 500
Epoch: 14 -- batch: 600
Epoch: 14 -- batch: 700
Epoch: 14 -- batch: 800
Epoch: 14 -- batch: 900
Epoch: 14 -- batch: 1000
Epoch: 14 -- batch: 1100
Epoch: 14 -- batch: 1200
Epoch: 14 -- batch: 1300
Epoch: 14 -- batch: 1400
Epoch: 14 -- batch: 1500
Epoch: 14 -- batch: 1600
Epoch: 14 -- batch: 1700
Epoch: 14 -- batch: 1800
Epoch: 14 -- batch: 1900
Epoch: 14 -- batch: 2000
Epoch: 14 -- batch: 2100
Epoch: 14 -- batch: 2200
Epoch: 14 -- batch: 2300
Epoch: 14 -- batch: 2400
Training time for epoch in sec:  2499.9604
End of epoch 14. Evaluation on dev.
Storing current model...
Loss: tensor(4.4011, device='cuda:0')
F1: 0.457489 (best: 0.462459)
Epoch: 15 -- batch: 0
Epoch: 15 -- batch: 100
Epoch: 15 -- batch: 200
Epoch: 15 -- batch: 300
Epoch: 15 -- batch: 400
Epoch: 15 -- batch: 500
Epoch: 15 -- batch: 600
Epoch: 15 -- batch: 700
Epoch: 15 -- batch: 800
Epoch: 15 -- batch: 900
Epoch: 15 -- batch: 1000
Epoch: 15 -- batch: 1100
Epoch: 15 -- batch: 1200
Epoch: 15 -- batch: 1300
Epoch: 15 -- batch: 1400
Epoch: 15 -- batch: 1500
Epoch: 15 -- batch: 1600
Epoch: 15 -- batch: 1700
Epoch: 15 -- batch: 1800
Epoch: 15 -- batch: 1900
Epoch: 15 -- batch: 2000
Epoch: 15 -- batch: 2100
Epoch: 15 -- batch: 2200
Epoch: 15 -- batch: 2300
Epoch: 15 -- batch: 2400
Training time for epoch in sec:  2497.3385
End of epoch 15. Evaluation on dev.
Storing current model...
Loss: tensor(4.3556, device='cuda:0')
F1: 0.458871 (best: 0.462459)
Epoch: 16 -- batch: 0
Epoch: 16 -- batch: 100
Epoch: 16 -- batch: 200
Epoch: 16 -- batch: 300
Epoch: 16 -- batch: 400
Epoch: 16 -- batch: 500
Epoch: 16 -- batch: 600
Epoch: 16 -- batch: 700
Epoch: 16 -- batch: 800
Epoch: 16 -- batch: 900
Epoch: 16 -- batch: 1000
Epoch: 16 -- batch: 1100
Epoch: 16 -- batch: 1200
Epoch: 16 -- batch: 1300
Epoch: 16 -- batch: 1400
Epoch: 16 -- batch: 1500
Epoch: 16 -- batch: 1600
Epoch: 16 -- batch: 1700
Epoch: 16 -- batch: 1800
Epoch: 16 -- batch: 1900
Epoch: 16 -- batch: 2000
Epoch: 16 -- batch: 2100
Epoch: 16 -- batch: 2200
Epoch: 16 -- batch: 2300
Epoch: 16 -- batch: 2400
Training time for epoch in sec:  2500.3174
End of epoch 16. Evaluation on dev.
Storing current model...
Loss: tensor(4.3146, device='cuda:0')
F1: 0.455799 (best: 0.462459)
Epoch: 17 -- batch: 0
Epoch: 17 -- batch: 100
Epoch: 17 -- batch: 200
Epoch: 17 -- batch: 300
Epoch: 17 -- batch: 400
Epoch: 17 -- batch: 500
Epoch: 17 -- batch: 600
Epoch: 17 -- batch: 700
Epoch: 17 -- batch: 800
Epoch: 17 -- batch: 900
Epoch: 17 -- batch: 1000
Epoch: 17 -- batch: 1100
Epoch: 17 -- batch: 1200
Epoch: 17 -- batch: 1300
Epoch: 17 -- batch: 1400
Epoch: 17 -- batch: 1500
Epoch: 17 -- batch: 1600
Epoch: 17 -- batch: 1700
Epoch: 17 -- batch: 1800
Epoch: 17 -- batch: 1900
Epoch: 17 -- batch: 2000
Epoch: 17 -- batch: 2100
Epoch: 17 -- batch: 2200
Epoch: 17 -- batch: 2300
Epoch: 17 -- batch: 2400
Training time for epoch in sec:  2500.3614
End of epoch 17. Evaluation on dev.
Storing current model...
Loss: tensor(4.2777, device='cuda:0')
F1: 0.459924 (best: 0.462459)
Epoch: 18 -- batch: 0
Epoch: 18 -- batch: 100
Epoch: 18 -- batch: 200
Epoch: 18 -- batch: 300
Epoch: 18 -- batch: 400
Epoch: 18 -- batch: 500
Epoch: 18 -- batch: 600
Epoch: 18 -- batch: 700
Epoch: 18 -- batch: 800
Epoch: 18 -- batch: 900
Epoch: 18 -- batch: 1000
Epoch: 18 -- batch: 1100
Epoch: 18 -- batch: 1200
Epoch: 18 -- batch: 1300
Epoch: 18 -- batch: 1400
Epoch: 18 -- batch: 1500
Epoch: 18 -- batch: 1600
Epoch: 18 -- batch: 1700
Epoch: 18 -- batch: 1800
Epoch: 18 -- batch: 1900
Epoch: 18 -- batch: 2000
Epoch: 18 -- batch: 2100
Epoch: 18 -- batch: 2200
Epoch: 18 -- batch: 2300
Epoch: 18 -- batch: 2400
Training time for epoch in sec:  2496.0343
End of epoch 18. Evaluation on dev.
Storing current model...
Loss: tensor(4.2421, device='cuda:0')
F1: 0.455273 (best: 0.462459)
Epoch: 19 -- batch: 0
Epoch: 19 -- batch: 100
Epoch: 19 -- batch: 200
Epoch: 19 -- batch: 300
Epoch: 19 -- batch: 400
Epoch: 19 -- batch: 500
Epoch: 19 -- batch: 600
Epoch: 19 -- batch: 700
Epoch: 19 -- batch: 800
Epoch: 19 -- batch: 900
Epoch: 19 -- batch: 1000
Epoch: 19 -- batch: 1100
Epoch: 19 -- batch: 1200
Epoch: 19 -- batch: 1300
Epoch: 19 -- batch: 1400
Epoch: 19 -- batch: 1500
Epoch: 19 -- batch: 1600
Epoch: 19 -- batch: 1700
Epoch: 19 -- batch: 1800
Epoch: 19 -- batch: 1900
Epoch: 19 -- batch: 2000
Epoch: 19 -- batch: 2100
Epoch: 19 -- batch: 2200
Epoch: 19 -- batch: 2300
Epoch: 19 -- batch: 2400
Training time for epoch in sec:  2496.2328
End of epoch 19. Evaluation on dev.
Storing current model...
Loss: tensor(4.2092, device='cuda:0')
F1: 0.450783 (best: 0.462459)
Epoch: 20 -- batch: 0
Epoch: 20 -- batch: 100
Epoch: 20 -- batch: 200
Epoch: 20 -- batch: 300
Epoch: 20 -- batch: 400
Epoch: 20 -- batch: 500
Epoch: 20 -- batch: 600
Epoch: 20 -- batch: 700
Epoch: 20 -- batch: 800
Epoch: 20 -- batch: 900
Epoch: 20 -- batch: 1000
Epoch: 20 -- batch: 1100
Epoch: 20 -- batch: 1200
Epoch: 20 -- batch: 1300
Epoch: 20 -- batch: 1400
Epoch: 20 -- batch: 1500
Epoch: 20 -- batch: 1600
Epoch: 20 -- batch: 1700
Epoch: 20 -- batch: 1800
Epoch: 20 -- batch: 1900
Epoch: 20 -- batch: 2000
Epoch: 20 -- batch: 2100
Epoch: 20 -- batch: 2200
Epoch: 20 -- batch: 2300
Epoch: 20 -- batch: 2400
Training time for epoch in sec:  2491.5445
End of epoch 20. Evaluation on dev.
Storing current model...
Loss: tensor(4.1767, device='cuda:0')
F1: 0.455536 (best: 0.462459)
Epoch: 21 -- batch: 0
Epoch: 21 -- batch: 100
Epoch: 21 -- batch: 200
Epoch: 21 -- batch: 300
Epoch: 21 -- batch: 400
Epoch: 21 -- batch: 500
Epoch: 21 -- batch: 600
Epoch: 21 -- batch: 700
Epoch: 21 -- batch: 800
Epoch: 21 -- batch: 900
Epoch: 21 -- batch: 1000
Epoch: 21 -- batch: 1100
Epoch: 21 -- batch: 1200
Epoch: 21 -- batch: 1300
Epoch: 21 -- batch: 1400
Epoch: 21 -- batch: 1500
Epoch: 21 -- batch: 1600
Epoch: 21 -- batch: 1700
Epoch: 21 -- batch: 1800
Epoch: 21 -- batch: 1900
Epoch: 21 -- batch: 2000
Epoch: 21 -- batch: 2100
Epoch: 21 -- batch: 2200
Epoch: 21 -- batch: 2300
Epoch: 21 -- batch: 2400
Training time for epoch in sec:  2491.3294
End of epoch 21. Evaluation on dev.
Storing current model...
Loss: tensor(4.1476, device='cuda:0')
F1: 0.45701 (best: 0.462459)
Epoch: 22 -- batch: 0
Epoch: 22 -- batch: 100
Epoch: 22 -- batch: 200
Epoch: 22 -- batch: 300
Epoch: 22 -- batch: 400
Epoch: 22 -- batch: 500
Epoch: 22 -- batch: 600
Epoch: 22 -- batch: 700
Epoch: 22 -- batch: 800
Epoch: 22 -- batch: 900
Epoch: 22 -- batch: 1000
Epoch: 22 -- batch: 1100
Epoch: 22 -- batch: 1200
Epoch: 22 -- batch: 1300
Epoch: 22 -- batch: 1400
Epoch: 22 -- batch: 1500
Epoch: 22 -- batch: 1600
Epoch: 22 -- batch: 1700
Epoch: 22 -- batch: 1800
Epoch: 22 -- batch: 1900
Epoch: 22 -- batch: 2000
Epoch: 22 -- batch: 2100
Epoch: 22 -- batch: 2200
Epoch: 22 -- batch: 2300
Epoch: 22 -- batch: 2400
Training time for epoch in sec:  2492.2192
End of epoch 22. Evaluation on dev.
Storing current model...
Loss: tensor(4.1216, device='cuda:0')
F1: 0.453573 (best: 0.462459)
Epoch: 23 -- batch: 0
Epoch: 23 -- batch: 100
Epoch: 23 -- batch: 200
Epoch: 23 -- batch: 300
Epoch: 23 -- batch: 400
Epoch: 23 -- batch: 500
Epoch: 23 -- batch: 600
Epoch: 23 -- batch: 700
Epoch: 23 -- batch: 800
Epoch: 23 -- batch: 900
Epoch: 23 -- batch: 1000
Epoch: 23 -- batch: 1100
Epoch: 23 -- batch: 1200
Epoch: 23 -- batch: 1300
Epoch: 23 -- batch: 1400
Epoch: 23 -- batch: 1500
Epoch: 23 -- batch: 1600
Epoch: 23 -- batch: 1700
Epoch: 23 -- batch: 1800
Epoch: 23 -- batch: 1900
Epoch: 23 -- batch: 2000
Epoch: 23 -- batch: 2100
Epoch: 23 -- batch: 2200
Epoch: 23 -- batch: 2300
Epoch: 23 -- batch: 2400
Training time for epoch in sec:  2492.2524
End of epoch 23. Evaluation on dev.
Storing current model...
Loss: tensor(4.0912, device='cuda:0')
F1: 0.453804 (best: 0.462459)
Epoch: 24 -- batch: 0
Epoch: 24 -- batch: 100
Epoch: 24 -- batch: 200
Epoch: 24 -- batch: 300
Epoch: 24 -- batch: 400
Epoch: 24 -- batch: 500
Epoch: 24 -- batch: 600
Epoch: 24 -- batch: 700
Epoch: 24 -- batch: 800
Epoch: 24 -- batch: 900
Epoch: 24 -- batch: 1000
Epoch: 24 -- batch: 1100
Epoch: 24 -- batch: 1200
Epoch: 24 -- batch: 1300
Epoch: 24 -- batch: 1400
Epoch: 24 -- batch: 1500
Epoch: 24 -- batch: 1600
Epoch: 24 -- batch: 1700
Epoch: 24 -- batch: 1800
Epoch: 24 -- batch: 1900
Epoch: 24 -- batch: 2000
Epoch: 24 -- batch: 2100
Epoch: 24 -- batch: 2200
Epoch: 24 -- batch: 2300
Epoch: 24 -- batch: 2400
Training time for epoch in sec:  2492.977
End of epoch 24. Evaluation on dev.
Storing current model...
Loss: tensor(4.0629, device='cuda:0')
F1: 0.457704 (best: 0.462459)
Epoch: 25 -- batch: 0
Epoch: 25 -- batch: 100
Epoch: 25 -- batch: 200
Epoch: 25 -- batch: 300
Epoch: 25 -- batch: 400
Epoch: 25 -- batch: 500
Epoch: 25 -- batch: 600
Epoch: 25 -- batch: 700
Epoch: 25 -- batch: 800
Epoch: 25 -- batch: 900
Epoch: 25 -- batch: 1000
Epoch: 25 -- batch: 1100
Epoch: 25 -- batch: 1200
Epoch: 25 -- batch: 1300
Epoch: 25 -- batch: 1400
Epoch: 25 -- batch: 1500
Epoch: 25 -- batch: 1600
Epoch: 25 -- batch: 1700
Epoch: 25 -- batch: 1800
Epoch: 25 -- batch: 1900
Epoch: 25 -- batch: 2000
Epoch: 25 -- batch: 2100
Epoch: 25 -- batch: 2200
Epoch: 25 -- batch: 2300
Epoch: 25 -- batch: 2400
Training time for epoch in sec:  2491.7287
End of epoch 25. Evaluation on dev.
Storing current model...
Loss: tensor(4.0396, device='cuda:0')
F1: 0.453867 (best: 0.462459)
Epoch: 26 -- batch: 0
Epoch: 26 -- batch: 100
Epoch: 26 -- batch: 200
Epoch: 26 -- batch: 300
Epoch: 26 -- batch: 400
Epoch: 26 -- batch: 500
Epoch: 26 -- batch: 600
Epoch: 26 -- batch: 700
Epoch: 26 -- batch: 800
Epoch: 26 -- batch: 900
Epoch: 26 -- batch: 1000
Epoch: 26 -- batch: 1100
Epoch: 26 -- batch: 1200
Epoch: 26 -- batch: 1300
Epoch: 26 -- batch: 1400
Epoch: 26 -- batch: 1500
Epoch: 26 -- batch: 1600
Epoch: 26 -- batch: 1700
Epoch: 26 -- batch: 1800
Epoch: 26 -- batch: 1900
Epoch: 26 -- batch: 2000
Epoch: 26 -- batch: 2100
Epoch: 26 -- batch: 2200
Epoch: 26 -- batch: 2300
Epoch: 26 -- batch: 2400
Training time for epoch in sec:  2491.0953
End of epoch 26. Evaluation on dev.
Storing current model...
Loss: tensor(4.0172, device='cuda:0')
F1: 0.458897 (best: 0.462459)
Epoch: 27 -- batch: 0
Epoch: 27 -- batch: 100
Epoch: 27 -- batch: 200
Epoch: 27 -- batch: 300
Epoch: 27 -- batch: 400
Epoch: 27 -- batch: 500
Epoch: 27 -- batch: 600
Epoch: 27 -- batch: 700
Epoch: 27 -- batch: 800
Epoch: 27 -- batch: 900
Epoch: 27 -- batch: 1000
Epoch: 27 -- batch: 1100
Epoch: 27 -- batch: 1200
Epoch: 27 -- batch: 1300
Epoch: 27 -- batch: 1400
Epoch: 27 -- batch: 1500
Epoch: 27 -- batch: 1600
Epoch: 27 -- batch: 1700
Epoch: 27 -- batch: 1800
Epoch: 27 -- batch: 1900
Epoch: 27 -- batch: 2000
Epoch: 27 -- batch: 2100
Epoch: 27 -- batch: 2200
Epoch: 27 -- batch: 2300
Epoch: 27 -- batch: 2400
Training time for epoch in sec:  2489.2415
End of epoch 27. Evaluation on dev.
Storing current model...
Loss: tensor(3.9931, device='cuda:0')
F1: 0.45532 (best: 0.462459)
Epoch: 28 -- batch: 0
Epoch: 28 -- batch: 100
Epoch: 28 -- batch: 200
Epoch: 28 -- batch: 300
Epoch: 28 -- batch: 400
Epoch: 28 -- batch: 500
Epoch: 28 -- batch: 600
Epoch: 28 -- batch: 700
Epoch: 28 -- batch: 800
Epoch: 28 -- batch: 900
Epoch: 28 -- batch: 1000
Epoch: 28 -- batch: 1100
Epoch: 28 -- batch: 1200
Epoch: 28 -- batch: 1300
Epoch: 28 -- batch: 1400
Epoch: 28 -- batch: 1500
Epoch: 28 -- batch: 1600
Epoch: 28 -- batch: 1700
Epoch: 28 -- batch: 1800
Epoch: 28 -- batch: 1900
Epoch: 28 -- batch: 2000
Epoch: 28 -- batch: 2100
Epoch: 28 -- batch: 2200
Epoch: 28 -- batch: 2300
Epoch: 28 -- batch: 2400
Training time for epoch in sec:  2491.3102
End of epoch 28. Evaluation on dev.
Storing current model...
Loss: tensor(3.9702, device='cuda:0')
F1: 0.453866 (best: 0.462459)
Epoch: 29 -- batch: 0
Epoch: 29 -- batch: 100
Epoch: 29 -- batch: 200
Epoch: 29 -- batch: 300
Epoch: 29 -- batch: 400
Epoch: 29 -- batch: 500
Epoch: 29 -- batch: 600
Epoch: 29 -- batch: 700
Epoch: 29 -- batch: 800
Epoch: 29 -- batch: 900
Epoch: 29 -- batch: 1000
Epoch: 29 -- batch: 1100
Epoch: 29 -- batch: 1200
Epoch: 29 -- batch: 1300
Epoch: 29 -- batch: 1400
Epoch: 29 -- batch: 1500
Epoch: 29 -- batch: 1600
Epoch: 29 -- batch: 1700
Epoch: 29 -- batch: 1800
Epoch: 29 -- batch: 1900
Epoch: 29 -- batch: 2000
Epoch: 29 -- batch: 2100
Epoch: 29 -- batch: 2200
Epoch: 29 -- batch: 2300
Epoch: 29 -- batch: 2400
Training time for epoch in sec:  2491.3346
End of epoch 29. Evaluation on dev.
Storing current model...
Loss: tensor(3.9474, device='cuda:0')
F1: 0.458199 (best: 0.462459)
